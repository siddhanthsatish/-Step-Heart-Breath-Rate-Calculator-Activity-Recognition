{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amended-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 146927 raw labelled activity data samples.\n",
      "Reorienting accelerometer data...\n",
      "Extracting features and labels for window size 20 and step size 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-098b7b258a6f>:56: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sampling_rate = n_samples / time_elapsed_seconds\n",
      "C:\\Users\\harsh\\assignment2_part1-team\\features.py:71: RuntimeWarning: divide by zero encountered in log\n",
      "  entropyy = -(data*np.log(np.abs(data)))\n",
      "C:\\Users\\harsh\\assignment2_part1-team\\features.py:71: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropyy = -(data*np.log(np.abs(data)))\n",
      "C:\\Users\\harsh\\assignment2_part1-team\\features.py:59: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.mean(np.fft.rfft(np.sqrt(window[0]**2+window[1]**2+window[2]**2), axis = 0).astype(float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction over 7346 windows\n",
      "Unique labels found: {1.0, 2.0, 3.0, 4.0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This is the script used to train an activity recognition \n",
    "classifier on accelerometer data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.tree import export_graphviz\n",
    "from features import extract_features\n",
    "from util import slidingWindow, reorient, reset_vars\n",
    "import pickle\n",
    "\n",
    "\n",
    "# %%---------------------------------------------------------------------------\n",
    "#\n",
    "#\t\t                 Load Data From Disk\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"Loading data...\")\n",
    "sys.stdout.flush()\n",
    "data_file = 'my-activity-data.csv'\n",
    "data = np.genfromtxt(data_file, delimiter=',')\n",
    "data = data[~np.isnan(data).any(axis=1)]\n",
    "print(\"Loaded {} raw labelled activity data samples.\".format(len(data)))\n",
    "sys.stdout.flush()\n",
    "\n",
    "# %%---------------------------------------------------------------------------\n",
    "#\n",
    "#\t\t                    Pre-processing\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"Reorienting accelerometer data...\")\n",
    "sys.stdout.flush()\n",
    "reset_vars()\n",
    "reoriented = np.asarray([reorient(data[i,1], data[i,2], data[i,3]) for i in range(len(data))])\n",
    "reoriented_data_with_timestamps = np.append(data[:,0:1],reoriented,axis=1)\n",
    "data = np.append(reoriented_data_with_timestamps, data[:,-1:], axis=1)\n",
    "\n",
    "# %%---------------------------------------------------------------------------\n",
    "#\n",
    "#\t\t                Extract Features & Labels\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "window_size = 20\n",
    "step_size = 20\n",
    "\n",
    "# sampling rate should be about 25 Hz; you can take a brief window to confirm this\n",
    "n_samples = 1000\n",
    "time_elapsed_seconds = (data[n_samples,0] - data[0,0]) / 1000\n",
    "sampling_rate = n_samples / time_elapsed_seconds\n",
    "\n",
    "# TODO: list the class labels that you collected data for in the order of label_index (defined while collecting data)\n",
    "class_names = [\"cycling\", \"hopping\", \"sitting\", \"walking\"] #...\n",
    "\n",
    "print(\"Extracting features and labels for window size {} and step size {}...\".format(window_size, step_size))\n",
    "sys.stdout.flush()\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i,window_with_timestamp_and_label in slidingWindow(data, window_size, step_size):\n",
    "    window = window_with_timestamp_and_label[:,1:-1] \n",
    "    feature_names, x = extract_features(window)\n",
    "    X.append(x)\n",
    "    Y.append(window_with_timestamp_and_label[10, -1])\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "n_features = len(X)\n",
    "    \n",
    "print(\"Finished feature extraction over {} windows\".format(len(X)))\n",
    "print(\"Unique labels found: {}\".format(set(Y)))\n",
    "print(\"\\n\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brave-adobe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7346\n",
      "Counter({2.0: 217, 1.0: 189, 3.0: 171, 4.0: 158})\n",
      "Counter({2.0: 209, 1.0: 198, 3.0: 166, 4.0: 162})\n",
      "Counter({2.0: 219, 3.0: 192, 1.0: 183, 4.0: 141})\n",
      "Counter({2.0: 225, 3.0: 184, 1.0: 178, 4.0: 148})\n",
      "Counter({1.0: 213, 2.0: 197, 3.0: 187, 4.0: 138})\n",
      "Counter({2.0: 216, 3.0: 189, 1.0: 178, 4.0: 152})\n",
      "Counter({2.0: 212, 1.0: 198, 3.0: 166, 4.0: 158})\n",
      "Counter({2.0: 206, 1.0: 196, 3.0: 193, 4.0: 139})\n",
      "Counter({1.0: 208, 2.0: 208, 3.0: 173, 4.0: 145})\n",
      "Counter({2.0: 202, 1.0: 199, 4.0: 177, 3.0: 156})\n",
      "Accuracy:  0.9115166175462012\n",
      "Precision:  [0.90947842 0.83926468 0.99322897 0.91775624]\n",
      "Recall:  [0.94718324 0.97210865 0.97214152 0.75497253]\n"
     ]
    }
   ],
   "source": [
    "# %%---------------------------------------------------------------------------\n",
    "#\n",
    "#\t\t                Train & Evaluate Classifier\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# TODO: split data into train and test datasets using 10-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# TODO: iterating over each fold, fit a decision tree classifier on the training set.\n",
    "# Then predict the class labels for the test set and compute the confusion matrix\n",
    "# using predicted labels and ground truth values. Print the accuracy, precision and recall\n",
    "# for each fold.\n",
    "# \"\"\"\n",
    "\n",
    "accuracy = precision = recall = 0\n",
    "# X = X[~np.isnan(X).any(axis=1)]\n",
    "print(len(X))\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=4)\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "#     print(y_pred)\n",
    "    from collections import Counter\n",
    "    print(Counter(y_pred))\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "    accuracy += accuracy_score(y_test, y_pred)\n",
    "    precision += precision_score(y_test, y_pred, average=None)\n",
    "    recall += recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "print(\"Accuracy: \", accuracy/10)\n",
    "print(\"Precision: \", precision/10)\n",
    "print(\"Recall: \", recall/10)\n",
    "\n",
    "# # TODO: calculate and print the average accuracy, precision and recall values over all 10 folds\n",
    "# TODO: train the decision tree classifier on entire dataset\n",
    "# TODO: Save the decision tree visualization to disk - replace 'tree' with your decision tree and run the below line\n",
    "\n",
    "\n",
    "\n",
    "export_graphviz(tree, out_file='tree.dot', feature_names = feature_names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Save the classifier to disk - replace 'tree' with your decision tree and run the below line\n",
    "\n",
    "\n",
    "with open('classifier.pickle', 'wb') as f:\n",
    "    pickle.dump(tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "literary-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identified-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 12041 raw labelled activity data samples.\n",
      "Reorienting accelerometer data...\n",
      "Extracting features and labels for window size 5 and step size 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\assignment2_part1-team\\features.py:71: RuntimeWarning: divide by zero encountered in log\n",
      "  entropyy = -(data*np.log(np.abs(data)))\n",
      "C:\\Users\\harsh\\assignment2_part1-team\\features.py:71: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropyy = -(data*np.log(np.abs(data)))\n",
      "C:\\Users\\harsh\\assignment2_part1-team\\features.py:59: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.mean(np.fft.rfft(np.sqrt(window[0]**2+window[1]**2+window[2]**2), axis = 0).astype(float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction over 2408 windows\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "sys.stdout.flush()\n",
    "data_file = 'testdata.csv'\n",
    "data = np.genfromtxt(data_file, delimiter=',')\n",
    "data = data[~np.isnan(data).any(axis=1)]\n",
    "print(\"Loaded {} raw labelled activity data samples.\".format(len(data)))\n",
    "sys.stdout.flush()\n",
    "\n",
    "# %%---------------------------------------------------------------------------\n",
    "#\n",
    "#\t\t                    Pre-processing\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"Reorienting accelerometer data...\")\n",
    "sys.stdout.flush()\n",
    "reset_vars()\n",
    "reoriented = np.asarray([reorient(data[i,1], data[i,2], data[i,3]) for i in range(len(data))])\n",
    "reoriented_data_with_timestamps = np.append(data[:,0:1],reoriented,axis=1)\n",
    "data = np.append(reoriented_data_with_timestamps, data[:,-1:], axis=1)\n",
    "\n",
    "window_size = 5\n",
    "step_size = 5\n",
    "\n",
    "# sampling rate should be about 25 Hz; you can take a brief window to confirm this\n",
    "n_samples = 1000\n",
    "time_elapsed_seconds = (data[n_samples,0] - data[0,0]) / 1000\n",
    "sampling_rate = n_samples / time_elapsed_seconds\n",
    "\n",
    "# TODO: list the class labels that you collected data for in the order of label_index (defined while collecting data)\n",
    "class_names = [\"cycling\", \"hopping\", \"sitting\", \"walking\"] #...\n",
    "\n",
    "print(\"Extracting features and labels for window size {} and step size {}...\".format(window_size, step_size))\n",
    "sys.stdout.flush()\n",
    "\n",
    "X = []\n",
    "\n",
    "for i,window_with_timestamp_and_label in slidingWindow(data, window_size, step_size):\n",
    "    window = window_with_timestamp_and_label[:,2:]\n",
    "    feature_names, x = extract_features(window)\n",
    "    X.append(x)\n",
    "\n",
    "X = np.asarray(X)\n",
    "\n",
    "n_features = len(X)\n",
    "    \n",
    "print(\"Finished feature extraction over {} windows\".format(len(X)))\n",
    "print(\"\\n\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seven-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2408\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('classifier.pickle', 'rb'))\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "prediction = loaded_model.predict(X)\n",
    "print(len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supported-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3.0: 1128, 1.0: 983, 2.0: 286, 4.0: 11})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-reverse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-kentucky",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
